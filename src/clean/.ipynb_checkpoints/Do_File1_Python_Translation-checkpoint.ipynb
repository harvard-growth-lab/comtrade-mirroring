{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc4d685f-79a4-4284-9e6e-d4c6c3544996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "# Import other necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d83bf-53fd-433e-8279-30b2e8a67fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _AtlasCleaning(object):\n",
    "    # Classification names & levels\n",
    "    PRODUCT_CLASSIFICATIONS = [\"H0\", \"HS\", \"S1\", \"S2\", \"ST\"]\n",
    "\n",
    "    HIERARCHY_LEVELS = {\n",
    "        \"hs92\": (1, 2, 4, 6),\n",
    "        \"hs12\": (1, 2, 4, 6),\n",
    "        \"sitc\": (1, 2, 4),\n",
    "        \"services\": (1, 2, 4, 6),\n",
    "    }\n",
    "\n",
    "    REGIONAL_GROUP_TYPES = [\"world\", \"region\", \"subregion\"]\n",
    "\n",
    "    INGESTION_OUTPUT_FORMATS = [\"parquet\", \"hdf5\"]\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        start_year,\n",
    "        end_year,\n",
    "        classification,\n",
    "        schema,\n",
    "        root_dir,\n",
    "        output_dir,\n",
    "    ):\n",
    "        # INPUTS\n",
    "        self.root_dir = data_dir\n",
    "        self.classification_dir = os.path.join(self.root_dir, \"classification\")\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "        self.df = None\n",
    "        self.latest_year = latest_year\n",
    "        self.earliest_year = latest_year - data_coverage_from_latest_year\n",
    "        self.limit_data_coverage = limit_data_coverage\n",
    "        self.product_classification = product_classification\n",
    "        self.schema = schema\n",
    "\n",
    "\n",
    "    def load_parquet(\n",
    "        self,\n",
    "        table_name: str,\n",
    "        schema: typing.Optional[str] = None,\n",
    "    ):\n",
    "        if schema is not None:\n",
    "            read_dir = os.path.join(self.root_dir, schema)\n",
    "        else:\n",
    "            read_dir = os.path.join(self.root_dir)\n",
    "\n",
    "        df = pd.read_parquet(os.path.join(read_dir, f\"{table_name}.parquet\"))\n",
    "        if self.limit_data_coverage and \"year\" in df.columns:\n",
    "            if schema == \"sitc\":\n",
    "                df = df[df.year >= (self.latest_year - 25)]\n",
    "            else:\n",
    "                df = df[df.year >= self.earliest_year]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def save_parquet(self, table_name: str):\n",
    "        if self.schema is not None:\n",
    "            save_dir = os.path.join(self.output_dir, self.schema)\n",
    "        else:\n",
    "            save_dir = os.path.join(self.output_dir)\n",
    "\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        save_path = os.path.join(save_dir, f\"{table_name}.parquet\")\n",
    "\n",
    "        self.df.to_parquet(save_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4953a4-d0a7-4531-966d-124a64ec6b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path\n",
    "path = \"/n/hausmann_lab/lab/atlas/bustos_yildirim/atlas_stata_cleaning/src\"\n",
    "data_path = os.path.join(path, \"data\")\n",
    "program_path = os.path.join(path, \"clean\", \"comtrade_reads_zip.py\")\n",
    "rfile_path = os.path.join(raw_data_path, f\"{classification}_{year}.zip\")\n",
    "\n",
    "\n",
    "# Define years\n",
    "startyear = 2015\n",
    "finalyear = 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca48c4-3107-478c-a100-3d452cb30ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(classification, year):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a641c8-fd77-4c6c-a10c-bb7eae8ed13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to clean data\n",
    "def cleandata(classification, year):\n",
    "    print(f\"   > {year} and classification = {classification}\")\n",
    "    \n",
    "    # Change directory to specific classification raw data and initialize paths\n",
    "    raw_data_path = os.path.join(path, f\"data/raw/{classification}_raw\")\n",
    "    program_path = os.path.join(path, \"clean\", \"comtrade_reads_zip.py\")\n",
    "    rfile_path = os.path.join(raw_data_path, f\"{classification}_{year}.zip\")\n",
    "    \n",
    "    # Load the temporary data\n",
    "    df = pd.read_stata(os.path.join(path, \"data/processed/prepped_{classification}_{year}.dta\"))\n",
    "\n",
    "    # Data manipulation based on 'classification'\n",
    "    # This is a simplification, adapt based on actual logic and conditions in Stata script\n",
    "    if classification in [\"H0\", \"HS\"]:\n",
    "        # Add \"00\" prefix to 'commoditycode' where the length of 'commoditycode' is 4 and 'agglevel' is 6\n",
    "        df['commodity_code'] = np.where((df['commodity_code'].str.len() == 4) & (df['agglevel'] == 6), '00' + df['commodity_code'], df['commodity_code'])\n",
    "        # Add \"0\" prefix to 'commoditycode' where the length of 'commoditycode' is 5 and 'agglevel' is 6\n",
    "        df['commodity_code'] = np.where((df['commodity_code'].str.len() == 5) & (df['agglevel'] == 6), '0' + df['commodity_code'], df['commodity_code'])\n",
    "        df['reporter_ansnoclas'] = df.trade_value.where((df.partner_iso==\"ANS\") & (df.agglevel == 4) & (df.commodity_code.str.slice(0, 4) == \"9999\"))\n",
    "\n",
    "    elif classification in [\"S1\", \"S1\", \"ST\"]:\n",
    "        # Add \"00\" prefix to 'commoditycode' where the length of 'commoditycode' is 2 and 'agglevel' is 4\n",
    "        df['commodity_code'] = np.where((df['commodity_code'].str.len() == 2) & (df['agglevel'] == 4), '00' + df['commodity_code'], df['commodity_code'])\n",
    "        # Add \"0\" prefix to 'commoditycode' where the length of 'commoditycode' is 3 and 'agglevel' is 4\n",
    "        df['commodity_code'] = np.where((df['commodity_code'].str.len() == 3) & (df['agglevel'] == 4), '0' + df['commodity_code'], df['commodity_code'])\n",
    "        df['reporter_ansnoclas'] = df.trade_value.where((df.partner_iso==\"ANS\") & (df.agglevel == 4) & (df.commodity_code == \"9310\"))\n",
    "\n",
    "    # handles Germany (reunification) and Russia\n",
    "    # drop if reporter and partner are DEU and DDR, trading with itself\n",
    "    df = df[~((df['reporter_iso'] == \"DEU\") & (df['partner_iso'] == \"DDR\"))]\n",
    "    df = df[~((df['reporter_iso'] == \"DDR\") & (df['partner_iso'] == \"DEU\"))]\n",
    "    df.loc[df['partner_iso'].isin([\"DEU\", \"DDR\"]), 'partner_iso'] = \"DEU\"\n",
    "    df.loc[df['reporter_iso'].isin([\"DEU\", \"DDR\"]), 'reporter_iso'] = \"DEU\"\n",
    "    df.loc[df['partner_iso'].isin([\"RUS\", \"SUN\"]), 'partner_iso'] = \"RUS\"\n",
    "    df.loc[df['reporter_iso'].isin([\"RUS\", \"SUN\"]), 'reporter_iso'] = \"RUS\"\n",
    "\n",
    "    #compress\n",
    "    #collapse (sum) tradevalue reporter_ansnoclas , by( year tradeflow agglevel reporter_iso partner_iso )\n",
    "    df_collapsed = df.groupby(['year', 'tradeflow', 'agglevel', 'reporter_iso', 'partner_iso']).agg({'tradevalue': 'sum', 'reporter_ansnoclas': 'sum'}).reset_index()\n",
    "    #recast float tradevalue reporter_ansnoclas, force\n",
    "    df_collapsed['tradevalue'] = df_collapsed['tradevalue'].astype('float')\n",
    "    df_collapsed['reporter_ansnoclas'] = df_collapsed['reporter_ansnoclas'].astype('float')\n",
    "\n",
    "    # Return the cleaned DataFrame\n",
    "    return df_collapsed\n",
    "\n",
    "\n",
    "# Loop over years and classifications, calling the cleandata function\n",
    "for year in range(startyear, finalyear + 1):\n",
    "    print(f\"> Doing year = {year}\")\n",
    "\n",
    "    # Example classifications processing, add as necessary\n",
    "    if 1976 <= year < 1995:\n",
    "        classification = \"S2\"\n",
    "        cleaned_data = cleandata(classification, year)\n",
    "        # Save cleaned data to file, replace `trade_S2` with actual path or filename\n",
    "        cleaned_data.to_csv(os.path.join(path, f\"Totals_raw_{year}.csv\"), index=False)\n",
    "\n",
    "    # Continue with other classification and year conditions\n",
    "\n",
    "# After processing all years and classifications, you might want to merge, manipulate,\n",
    "# and analyze the cleaned datasets similarly to how it's done in the Stata script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe839d-8a1e-4eff-8ca2-a9a66954c045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
